{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# APIM ‚ù§Ô∏è OpenAI\n",
    "\n",
    "## Azure OpenAI Realtime Audio lab\n",
    "![flow](../../images/realtime-audio.gif)\n",
    "\n",
    "Playground to try the APIM integration with the [Azure OpenAI Realtime API](https://learn.microsoft.com/en-us/azure/ai-services/openai/realtime-audio-reference) for text and audio.\n",
    "\n",
    "### Result\n",
    "![result](result.png)\n",
    "\n",
    "### Prerequisites\n",
    "\n",
    "- [Python 3.12 or later version](https://www.python.org/) installed\n",
    "- [VS Code](https://code.visualstudio.com/) installed with the [Jupyter notebook extension](https://marketplace.visualstudio.com/items?itemName=ms-toolsai.jupyter) enabled\n",
    "- [Python environment](https://code.visualstudio.com/docs/python/environments#_creating-environments) with the [requirements.txt](../../requirements.txt) or run `pip install -r requirements.txt` in your terminal\n",
    "- [An Azure Subscription](https://azure.microsoft.com/free/) with [Contributor](https://learn.microsoft.com/en-us/azure/role-based-access-control/built-in-roles/privileged#contributor) + [RBAC Administrator](https://learn.microsoft.com/en-us/azure/role-based-access-control/built-in-roles/privileged#role-based-access-control-administrator) or [Owner](https://learn.microsoft.com/en-us/azure/role-based-access-control/built-in-roles/privileged#owner) roles\n",
    "- [Azure CLI](https://learn.microsoft.com/cli/azure/install-azure-cli) installed and [Signed into your Azure subscription](https://learn.microsoft.com/cli/azure/authenticate-azure-cli-interactively)\n",
    "\n",
    "‚ñ∂Ô∏è Click `Run All` to execute all steps sequentially, or execute them `Step by Step`...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='0'></a>\n",
    "### 0Ô∏è‚É£ Initialize notebook variables\n",
    "\n",
    "- Resources will be suffixed by a unique string based on your subscription id.\n",
    "- Adjust the location parameters according your preferences and on the [product availability by Azure region.](https://azure.microsoft.com/explore/global-infrastructure/products-by-region/?cdn=disable&products=cognitive-services,api-management)\n",
    "- Adjust the OpenAI model and version according the [availability by region.](https://learn.microsoft.com/azure/ai-services/openai/concepts/models) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ \u001b[1;32mNotebook initialized\u001b[0m ‚åö 19:17:29.097410 \n"
     ]
    }
   ],
   "source": [
    "import os, sys, json\n",
    "sys.path.insert(1, '../../shared')  # add the shared directory to the Python path\n",
    "import utils\n",
    "\n",
    "deployment_name = os.path.basename(os.path.dirname(globals()['__vsc_ipynb_file__']))\n",
    "resource_group_name = f\"lab-{deployment_name}\" # change the name to match your naming style\n",
    "resource_group_location = \"eastus2\" \n",
    "\n",
    "apim_sku = 'Basicv2'\n",
    "\n",
    "# gpt-4o-realtime and gpt-4o-mini-realtime are only available for eastuse2 or swedencentral\n",
    "openai_resources = [\n",
    "    {\"name\": \"openai1\", \"location\": \"eastus2\"},\n",
    "]\n",
    "\n",
    "openai_deployment_name = \"gpt-4o-realtime-preview\"\n",
    "openai_model_name = \"gpt-4o-realtime-preview\"\n",
    "openai_model_version = \"2024-12-17\"\n",
    "openai_model_capacity = 6\n",
    "openai_model_sku = 'GlobalStandard'\n",
    "openai_api_version = \"2024-10-01-preview\"\n",
    "\n",
    "utils.print_ok('Notebook initialized')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='1'></a>\n",
    "### 1Ô∏è‚É£ Verify the Azure CLI and the connected Azure subscription\n",
    "\n",
    "The following commands ensure that you have the latest version of the Azure CLI and that the Azure CLI is connected to your Azure subscription."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚öôÔ∏è \u001b[1;34mRunning: az account show \u001b[0m\n",
      "‚úÖ \u001b[1;32mRetrieved az account\u001b[0m ‚åö 19:17:31.894133 [0m:2s]\n",
      "üëâüèΩ \u001b[1;34mCurrent user: alexviei@microsoft.com\u001b[0m\n",
      "üëâüèΩ \u001b[1;34mTenant ID: 16b3c013-d300-468d-ac64-7eda0820b6d3\u001b[0m\n",
      "üëâüèΩ \u001b[1;34mSubscription ID: 9d4a14de-67d7-4029-a3b4-7a7e3e6581cf\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "output = utils.run(\"az account show\", \"Retrieved az account\", \"Failed to get the current az account\")\n",
    "\n",
    "if output.success and output.json_data:\n",
    "    current_user = output.json_data['user']['name']\n",
    "    tenant_id = output.json_data['tenantId']\n",
    "    subscription_id = output.json_data['id']\n",
    "\n",
    "    utils.print_info(f\"Current user: {current_user}\")\n",
    "    utils.print_info(f\"Tenant ID: {tenant_id}\")\n",
    "    utils.print_info(f\"Subscription ID: {subscription_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='2'></a>\n",
    "### 2Ô∏è‚É£ Create deployment using ü¶æ Bicep\n",
    "\n",
    "This lab uses [Bicep](https://learn.microsoft.com/azure/azure-resource-manager/bicep/overview?tabs=bicep) to declarative define all the resources that will be deployed in the specified resource group. Change the parameters or the [main.bicep](main.bicep) directly to try different configurations.\n",
    "\n",
    "`openAIModelCapacity` is set intentionally low to `6` (6k tokens per minute) to trigger the retry logic in the load balancer (transparent to the user) as well as the priority failover from priority 1 to 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚öôÔ∏è \u001b[1;34mRunning: az group show --name lab-realtime-audio \u001b[0m\n",
      "üëâüèΩ \u001b[1;34mResource group lab-realtime-audio does not yet exist. Creating the resource group now...\u001b[0m\n",
      "‚öôÔ∏è \u001b[1;34mRunning: az group create --name lab-realtime-audio --location eastus2 --tags source=ai-gateway \u001b[0m\n",
      "‚úÖ \u001b[1;32mResource group 'lab-realtime-audio' created\u001b[0m ‚åö 19:17:40.634412 [0m:4s]\n",
      "‚öôÔ∏è \u001b[1;34mRunning: az deployment group create --name realtime-audio --resource-group lab-realtime-audio --template-file main.bicep --parameters params.json \u001b[0m\n",
      "‚úÖ \u001b[1;32mDeployment 'realtime-audio' succeeded\u001b[0m ‚åö 19:20:39.987497 [2m:59s]\n"
     ]
    }
   ],
   "source": [
    "# Create the resource group if doesn't exist\n",
    "utils.create_resource_group(resource_group_name, resource_group_location)\n",
    "\n",
    "# Define the Bicep parameters\n",
    "bicep_parameters = {\n",
    "    \"$schema\": \"https://schema.management.azure.com/schemas/2019-04-01/deploymentParameters.json#\",\n",
    "    \"contentVersion\": \"1.0.0.0\",\n",
    "    \"parameters\": {\n",
    "        \"apimSku\": { \"value\": apim_sku },\n",
    "        \"openAIConfig\": { \"value\": openai_resources },\n",
    "        \"openAIDeploymentName\": { \"value\": openai_deployment_name },\n",
    "        \"openAIModelName\": { \"value\": openai_model_name },\n",
    "        \"openAIModelVersion\": { \"value\": openai_model_version },\n",
    "        \"openAIModelCapacity\": { \"value\": openai_model_capacity },\n",
    "        \"openAIModelSKU\": { \"value\": openai_model_sku },\n",
    "    }\n",
    "}\n",
    "\n",
    "# Write the parameters to the params.json file\n",
    "with open('params.json', 'w') as bicep_parameters_file:\n",
    "    bicep_parameters_file.write(json.dumps(bicep_parameters))\n",
    "\n",
    "# Run the deployment\n",
    "output = utils.run(f\"az deployment group create --name {deployment_name} --resource-group {resource_group_name} --template-file main.bicep --parameters params.json\",\n",
    "    f\"Deployment '{deployment_name}' succeeded\", f\"Deployment '{deployment_name}' failed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='3'></a>\n",
    "### 3Ô∏è‚É£ Get the deployment outputs\n",
    "\n",
    "Retrieve the required outputs from the Bicep deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚öôÔ∏è \u001b[1;34mRunning: az deployment group show --name realtime-audio -g lab-realtime-audio \u001b[0m\n",
      "‚úÖ \u001b[1;32mRetrieved deployment: realtime-audio\u001b[0m ‚åö 19:20:45.847701 [0m:5s]\n",
      "üëâüèΩ \u001b[1;34mAPIM Service Id: /subscriptions/9d4a14de-67d7-4029-a3b4-7a7e3e6581cf/resourceGroups/lab-realtime-audio/providers/Microsoft.ApiManagement/service/apim-sjvzedbft54iy\u001b[0m\n",
      "üëâüèΩ \u001b[1;34mAPIM API Gateway URL: https://apim-sjvzedbft54iy.azure-api.net\u001b[0m\n",
      "üëâüèΩ \u001b[1;34mAPIM Subscription Key (masked): ****0d2e\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Obtain all of the outputs from the deployment\n",
    "output = utils.run(f\"az deployment group show --name {deployment_name} -g {resource_group_name}\", f\"Retrieved deployment: {deployment_name}\", f\"Failed to retrieve deployment: {deployment_name}\")\n",
    "\n",
    "if output.success and output.json_data:\n",
    "    apim_service_id = utils.get_deployment_output(output, 'apimServiceId', 'APIM Service Id')\n",
    "    apim_resource_gateway_url = utils.get_deployment_output(output, 'apimResourceGatewayURL', 'APIM API Gateway URL')\n",
    "    apim_subscription_key = utils.get_deployment_output(output, 'apimSubscriptionKey', 'APIM Subscription Key (masked)', True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='4'></a>\n",
    "### 4 Install Python library requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: aiohttp in c:\\projects\\ai-gateway\\.venv\\lib\\site-packages (from -r requirements.txt (line 1)) (3.11.16)\n",
      "Requirement already satisfied: openai==1.71.0 in c:\\projects\\ai-gateway\\.venv\\lib\\site-packages (from -r requirements.txt (line 2)) (1.71.0)\n",
      "Requirement already satisfied: azure-identity in c:\\projects\\ai-gateway\\.venv\\lib\\site-packages (from -r requirements.txt (line 5)) (1.20.0)\n",
      "Requirement already satisfied: fastrtc[vad] in c:\\projects\\ai-gateway\\.venv\\lib\\site-packages (from -r requirements.txt (line 4)) (0.0.20)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\projects\\ai-gateway\\.venv\\lib\\site-packages (from openai==1.71.0->-r requirements.txt (line 2)) (4.8.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\projects\\ai-gateway\\.venv\\lib\\site-packages (from openai==1.71.0->-r requirements.txt (line 2)) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\projects\\ai-gateway\\.venv\\lib\\site-packages (from openai==1.71.0->-r requirements.txt (line 2)) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\projects\\ai-gateway\\.venv\\lib\\site-packages (from openai==1.71.0->-r requirements.txt (line 2)) (0.8.2)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\projects\\ai-gateway\\.venv\\lib\\site-packages (from openai==1.71.0->-r requirements.txt (line 2)) (2.10.6)\n",
      "Requirement already satisfied: sniffio in c:\\projects\\ai-gateway\\.venv\\lib\\site-packages (from openai==1.71.0->-r requirements.txt (line 2)) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\projects\\ai-gateway\\.venv\\lib\\site-packages (from openai==1.71.0->-r requirements.txt (line 2)) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\projects\\ai-gateway\\.venv\\lib\\site-packages (from openai==1.71.0->-r requirements.txt (line 2)) (4.12.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\projects\\ai-gateway\\.venv\\lib\\site-packages (from aiohttp->-r requirements.txt (line 1)) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\projects\\ai-gateway\\.venv\\lib\\site-packages (from aiohttp->-r requirements.txt (line 1)) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\projects\\ai-gateway\\.venv\\lib\\site-packages (from aiohttp->-r requirements.txt (line 1)) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\projects\\ai-gateway\\.venv\\lib\\site-packages (from aiohttp->-r requirements.txt (line 1)) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\projects\\ai-gateway\\.venv\\lib\\site-packages (from aiohttp->-r requirements.txt (line 1)) (6.4.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\projects\\ai-gateway\\.venv\\lib\\site-packages (from aiohttp->-r requirements.txt (line 1)) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\projects\\ai-gateway\\.venv\\lib\\site-packages (from aiohttp->-r requirements.txt (line 1)) (1.19.0)\n",
      "Requirement already satisfied: websockets<16,>=13 in c:\\projects\\ai-gateway\\.venv\\lib\\site-packages (from openai[realtime]->-r requirements.txt (line 3)) (15.0.1)\n",
      "Requirement already satisfied: aiortc in c:\\projects\\ai-gateway\\.venv\\lib\\site-packages (from fastrtc[vad]->-r requirements.txt (line 4)) (1.11.0)\n",
      "Requirement already satisfied: gradio<6.0,>=4.0 in c:\\projects\\ai-gateway\\.venv\\lib\\site-packages (from fastrtc[vad]->-r requirements.txt (line 4)) (5.25.1)\n",
      "Requirement already satisfied: librosa in c:\\projects\\ai-gateway\\.venv\\lib\\site-packages (from fastrtc[vad]->-r requirements.txt (line 4)) (0.11.0)\n",
      "Requirement already satisfied: numba>=0.60.0 in c:\\projects\\ai-gateway\\.venv\\lib\\site-packages (from fastrtc[vad]->-r requirements.txt (line 4)) (0.61.2)\n",
      "Requirement already satisfied: numpy>=2.0.2 in c:\\projects\\ai-gateway\\.venv\\lib\\site-packages (from fastrtc[vad]->-r requirements.txt (line 4)) (2.2.3)\n",
      "Requirement already satisfied: onnxruntime>=1.20.1 in c:\\projects\\ai-gateway\\.venv\\lib\\site-packages (from fastrtc[vad]->-r requirements.txt (line 4)) (1.21.0)\n",
      "Requirement already satisfied: azure-core>=1.31.0 in c:\\projects\\ai-gateway\\.venv\\lib\\site-packages (from azure-identity->-r requirements.txt (line 5)) (1.32.0)\n",
      "Requirement already satisfied: cryptography>=2.5 in c:\\projects\\ai-gateway\\.venv\\lib\\site-packages (from azure-identity->-r requirements.txt (line 5)) (44.0.1)\n",
      "Requirement already satisfied: msal>=1.30.0 in c:\\projects\\ai-gateway\\.venv\\lib\\site-packages (from azure-identity->-r requirements.txt (line 5)) (1.31.2b1)\n",
      "Requirement already satisfied: msal-extensions>=1.2.0 in c:\\projects\\ai-gateway\\.venv\\lib\\site-packages (from azure-identity->-r requirements.txt (line 5)) (1.2.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\projects\\ai-gateway\\.venv\\lib\\site-packages (from anyio<5,>=3.5.0->openai==1.71.0->-r requirements.txt (line 2)) (3.10)\n",
      "Requirement already satisfied: requests>=2.21.0 in c:\\projects\\ai-gateway\\.venv\\lib\\site-packages (from azure-core>=1.31.0->azure-identity->-r requirements.txt (line 5)) (2.32.3)\n",
      "Requirement already satisfied: six>=1.11.0 in c:\\projects\\ai-gateway\\.venv\\lib\\site-packages (from azure-core>=1.31.0->azure-identity->-r requirements.txt (line 5)) (1.17.0)\n",
      "Requirement already satisfied: cffi>=1.12 in c:\\projects\\ai-gateway\\.venv\\lib\\site-packages (from cryptography>=2.5->azure-identity->-r requirements.txt (line 5)) (1.17.1)\n",
      "Requirement already satisfied: aiofiles<25.0,>=22.0 in c:\\projects\\ai-gateway\\.venv\\lib\\site-packages (from gradio<6.0,>=4.0->fastrtc[vad]->-r requirements.txt (line 4)) (24.1.0)\n",
      "Requirement already satisfied: fastapi<1.0,>=0.115.2 in c:\\projects\\ai-gateway\\.venv\\lib\\site-packages (from gradio<6.0,>=4.0->fastrtc[vad]->-r requirements.txt (line 4)) (0.115.12)\n",
      "Requirement already satisfied: ffmpy in c:\\projects\\ai-gateway\\.venv\\lib\\site-packages (from gradio<6.0,>=4.0->fastrtc[vad]->-r requirements.txt (line 4)) (0.5.0)\n",
      "Requirement already satisfied: gradio-client==1.8.0 in c:\\projects\\ai-gateway\\.venv\\lib\\site-packages (from gradio<6.0,>=4.0->fastrtc[vad]->-r requirements.txt (line 4)) (1.8.0)\n",
      "Requirement already satisfied: groovy~=0.1 in c:\\projects\\ai-gateway\\.venv\\lib\\site-packages (from gradio<6.0,>=4.0->fastrtc[vad]->-r requirements.txt (line 4)) (0.1.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.28.1 in c:\\projects\\ai-gateway\\.venv\\lib\\site-packages (from gradio<6.0,>=4.0->fastrtc[vad]->-r requirements.txt (line 4)) (0.30.2)\n",
      "Requirement already satisfied: jinja2<4.0 in c:\\projects\\ai-gateway\\.venv\\lib\\site-packages (from gradio<6.0,>=4.0->fastrtc[vad]->-r requirements.txt (line 4)) (3.1.6)\n",
      "Requirement already satisfied: markupsafe<4.0,>=2.0 in c:\\projects\\ai-gateway\\.venv\\lib\\site-packages (from gradio<6.0,>=4.0->fastrtc[vad]->-r requirements.txt (line 4)) (3.0.2)\n",
      "Requirement already satisfied: orjson~=3.0 in c:\\projects\\ai-gateway\\.venv\\lib\\site-packages (from gradio<6.0,>=4.0->fastrtc[vad]->-r requirements.txt (line 4)) (3.10.16)\n",
      "Requirement already satisfied: packaging in c:\\projects\\ai-gateway\\.venv\\lib\\site-packages (from gradio<6.0,>=4.0->fastrtc[vad]->-r requirements.txt (line 4)) (24.2)\n",
      "Requirement already satisfied: pandas<3.0,>=1.0 in c:\\projects\\ai-gateway\\.venv\\lib\\site-packages (from gradio<6.0,>=4.0->fastrtc[vad]->-r requirements.txt (line 4)) (2.2.3)\n",
      "Requirement already satisfied: pillow<12.0,>=8.0 in c:\\projects\\ai-gateway\\.venv\\lib\\site-packages (from gradio<6.0,>=4.0->fastrtc[vad]->-r requirements.txt (line 4)) (11.1.0)\n",
      "Requirement already satisfied: pydub in c:\\projects\\ai-gateway\\.venv\\lib\\site-packages (from gradio<6.0,>=4.0->fastrtc[vad]->-r requirements.txt (line 4)) (0.25.1)\n",
      "Requirement already satisfied: python-multipart>=0.0.18 in c:\\projects\\ai-gateway\\.venv\\lib\\site-packages (from gradio<6.0,>=4.0->fastrtc[vad]->-r requirements.txt (line 4)) (0.0.20)\n",
      "Requirement already satisfied: pyyaml<7.0,>=5.0 in c:\\projects\\ai-gateway\\.venv\\lib\\site-packages (from gradio<6.0,>=4.0->fastrtc[vad]->-r requirements.txt (line 4)) (6.0.2)\n",
      "Requirement already satisfied: ruff>=0.9.3 in c:\\projects\\ai-gateway\\.venv\\lib\\site-packages (from gradio<6.0,>=4.0->fastrtc[vad]->-r requirements.txt (line 4)) (0.11.5)\n",
      "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in c:\\projects\\ai-gateway\\.venv\\lib\\site-packages (from gradio<6.0,>=4.0->fastrtc[vad]->-r requirements.txt (line 4)) (0.1.6)\n",
      "Requirement already satisfied: semantic-version~=2.0 in c:\\projects\\ai-gateway\\.venv\\lib\\site-packages (from gradio<6.0,>=4.0->fastrtc[vad]->-r requirements.txt (line 4)) (2.10.0)\n",
      "Requirement already satisfied: starlette<1.0,>=0.40.0 in c:\\projects\\ai-gateway\\.venv\\lib\\site-packages (from gradio<6.0,>=4.0->fastrtc[vad]->-r requirements.txt (line 4)) (0.46.1)\n",
      "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in c:\\projects\\ai-gateway\\.venv\\lib\\site-packages (from gradio<6.0,>=4.0->fastrtc[vad]->-r requirements.txt (line 4)) (0.13.2)\n",
      "Requirement already satisfied: typer<1.0,>=0.12 in c:\\projects\\ai-gateway\\.venv\\lib\\site-packages (from gradio<6.0,>=4.0->fastrtc[vad]->-r requirements.txt (line 4)) (0.15.2)\n",
      "Requirement already satisfied: uvicorn>=0.14.0 in c:\\projects\\ai-gateway\\.venv\\lib\\site-packages (from gradio<6.0,>=4.0->fastrtc[vad]->-r requirements.txt (line 4)) (0.34.0)\n",
      "Requirement already satisfied: fsspec in c:\\projects\\ai-gateway\\.venv\\lib\\site-packages (from gradio-client==1.8.0->gradio<6.0,>=4.0->fastrtc[vad]->-r requirements.txt (line 4)) (2025.3.2)\n",
      "Requirement already satisfied: certifi in c:\\projects\\ai-gateway\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->openai==1.71.0->-r requirements.txt (line 2)) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\projects\\ai-gateway\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->openai==1.71.0->-r requirements.txt (line 2)) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\projects\\ai-gateway\\.venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai==1.71.0->-r requirements.txt (line 2)) (0.14.0)\n",
      "Requirement already satisfied: PyJWT<3,>=1.0.0 in c:\\projects\\ai-gateway\\.venv\\lib\\site-packages (from PyJWT[crypto]<3,>=1.0.0->msal>=1.30.0->azure-identity->-r requirements.txt (line 5)) (2.10.1)\n",
      "Requirement already satisfied: portalocker<3,>=1.4 in c:\\projects\\ai-gateway\\.venv\\lib\\site-packages (from msal-extensions>=1.2.0->azure-identity->-r requirements.txt (line 5)) (2.10.1)\n",
      "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in c:\\projects\\ai-gateway\\.venv\\lib\\site-packages (from numba>=0.60.0->fastrtc[vad]->-r requirements.txt (line 4)) (0.44.0)\n",
      "Requirement already satisfied: coloredlogs in c:\\projects\\ai-gateway\\.venv\\lib\\site-packages (from onnxruntime>=1.20.1->fastrtc[vad]->-r requirements.txt (line 4)) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in c:\\projects\\ai-gateway\\.venv\\lib\\site-packages (from onnxruntime>=1.20.1->fastrtc[vad]->-r requirements.txt (line 4)) (25.2.10)\n",
      "Requirement already satisfied: protobuf in c:\\projects\\ai-gateway\\.venv\\lib\\site-packages (from onnxruntime>=1.20.1->fastrtc[vad]->-r requirements.txt (line 4)) (5.29.4)\n",
      "Requirement already satisfied: sympy in c:\\projects\\ai-gateway\\.venv\\lib\\site-packages (from onnxruntime>=1.20.1->fastrtc[vad]->-r requirements.txt (line 4)) (1.13.3)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\projects\\ai-gateway\\.venv\\lib\\site-packages (from pydantic<3,>=1.9.0->openai==1.71.0->-r requirements.txt (line 2)) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\projects\\ai-gateway\\.venv\\lib\\site-packages (from pydantic<3,>=1.9.0->openai==1.71.0->-r requirements.txt (line 2)) (2.27.2)\n",
      "Requirement already satisfied: colorama in c:\\projects\\ai-gateway\\.venv\\lib\\site-packages (from tqdm>4->openai==1.71.0->-r requirements.txt (line 2)) (0.4.6)\n",
      "Requirement already satisfied: aioice<1.0.0,>=0.9.0 in c:\\projects\\ai-gateway\\.venv\\lib\\site-packages (from aiortc->fastrtc[vad]->-r requirements.txt (line 4)) (0.10.1)\n",
      "Requirement already satisfied: av<15.0.0,>=14.0.0 in c:\\projects\\ai-gateway\\.venv\\lib\\site-packages (from aiortc->fastrtc[vad]->-r requirements.txt (line 4)) (14.3.0)\n",
      "Requirement already satisfied: google-crc32c>=1.1 in c:\\projects\\ai-gateway\\.venv\\lib\\site-packages (from aiortc->fastrtc[vad]->-r requirements.txt (line 4)) (1.7.1)\n",
      "Requirement already satisfied: pyee>=13.0.0 in c:\\projects\\ai-gateway\\.venv\\lib\\site-packages (from aiortc->fastrtc[vad]->-r requirements.txt (line 4)) (13.0.0)\n",
      "Requirement already satisfied: pylibsrtp>=0.10.0 in c:\\projects\\ai-gateway\\.venv\\lib\\site-packages (from aiortc->fastrtc[vad]->-r requirements.txt (line 4)) (0.12.0)\n",
      "Requirement already satisfied: pyopenssl>=25.0.0 in c:\\projects\\ai-gateway\\.venv\\lib\\site-packages (from aiortc->fastrtc[vad]->-r requirements.txt (line 4)) (25.0.0)\n",
      "Requirement already satisfied: audioread>=2.1.9 in c:\\projects\\ai-gateway\\.venv\\lib\\site-packages (from librosa->fastrtc[vad]->-r requirements.txt (line 4)) (3.0.1)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\projects\\ai-gateway\\.venv\\lib\\site-packages (from librosa->fastrtc[vad]->-r requirements.txt (line 4)) (1.15.2)\n",
      "Requirement already satisfied: scikit-learn>=1.1.0 in c:\\projects\\ai-gateway\\.venv\\lib\\site-packages (from librosa->fastrtc[vad]->-r requirements.txt (line 4)) (1.6.1)\n",
      "Requirement already satisfied: joblib>=1.0 in c:\\projects\\ai-gateway\\.venv\\lib\\site-packages (from librosa->fastrtc[vad]->-r requirements.txt (line 4)) (1.4.2)\n",
      "Requirement already satisfied: decorator>=4.3.0 in c:\\projects\\ai-gateway\\.venv\\lib\\site-packages (from librosa->fastrtc[vad]->-r requirements.txt (line 4)) (5.2.1)\n",
      "Requirement already satisfied: soundfile>=0.12.1 in c:\\projects\\ai-gateway\\.venv\\lib\\site-packages (from librosa->fastrtc[vad]->-r requirements.txt (line 4)) (0.13.1)\n",
      "Requirement already satisfied: pooch>=1.1 in c:\\projects\\ai-gateway\\.venv\\lib\\site-packages (from librosa->fastrtc[vad]->-r requirements.txt (line 4)) (1.8.2)\n",
      "Requirement already satisfied: soxr>=0.3.2 in c:\\projects\\ai-gateway\\.venv\\lib\\site-packages (from librosa->fastrtc[vad]->-r requirements.txt (line 4)) (0.5.0.post1)\n",
      "Requirement already satisfied: lazy_loader>=0.1 in c:\\projects\\ai-gateway\\.venv\\lib\\site-packages (from librosa->fastrtc[vad]->-r requirements.txt (line 4)) (0.4)\n",
      "Requirement already satisfied: msgpack>=1.0 in c:\\projects\\ai-gateway\\.venv\\lib\\site-packages (from librosa->fastrtc[vad]->-r requirements.txt (line 4)) (1.1.0)\n",
      "Requirement already satisfied: dnspython>=2.0.0 in c:\\projects\\ai-gateway\\.venv\\lib\\site-packages (from aioice<1.0.0,>=0.9.0->aiortc->fastrtc[vad]->-r requirements.txt (line 4)) (2.7.0)\n",
      "Requirement already satisfied: ifaddr>=0.2.0 in c:\\projects\\ai-gateway\\.venv\\lib\\site-packages (from aioice<1.0.0,>=0.9.0->aiortc->fastrtc[vad]->-r requirements.txt (line 4)) (0.2.0)\n",
      "Requirement already satisfied: pycparser in c:\\projects\\ai-gateway\\.venv\\lib\\site-packages (from cffi>=1.12->cryptography>=2.5->azure-identity->-r requirements.txt (line 5)) (2.22)\n",
      "Requirement already satisfied: filelock in c:\\projects\\ai-gateway\\.venv\\lib\\site-packages (from huggingface-hub>=0.28.1->gradio<6.0,>=4.0->fastrtc[vad]->-r requirements.txt (line 4)) (3.18.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\projects\\ai-gateway\\.venv\\lib\\site-packages (from pandas<3.0,>=1.0->gradio<6.0,>=4.0->fastrtc[vad]->-r requirements.txt (line 4)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\projects\\ai-gateway\\.venv\\lib\\site-packages (from pandas<3.0,>=1.0->gradio<6.0,>=4.0->fastrtc[vad]->-r requirements.txt (line 4)) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\projects\\ai-gateway\\.venv\\lib\\site-packages (from pandas<3.0,>=1.0->gradio<6.0,>=4.0->fastrtc[vad]->-r requirements.txt (line 4)) (2025.1)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in c:\\projects\\ai-gateway\\.venv\\lib\\site-packages (from pooch>=1.1->librosa->fastrtc[vad]->-r requirements.txt (line 4)) (4.3.6)\n",
      "Requirement already satisfied: pywin32>=226 in c:\\projects\\ai-gateway\\.venv\\lib\\site-packages (from portalocker<3,>=1.4->msal-extensions>=1.2.0->azure-identity->-r requirements.txt (line 5)) (308)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\projects\\ai-gateway\\.venv\\lib\\site-packages (from requests>=2.21.0->azure-core>=1.31.0->azure-identity->-r requirements.txt (line 5)) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\projects\\ai-gateway\\.venv\\lib\\site-packages (from requests>=2.21.0->azure-core>=1.31.0->azure-identity->-r requirements.txt (line 5)) (2.3.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\projects\\ai-gateway\\.venv\\lib\\site-packages (from scikit-learn>=1.1.0->librosa->fastrtc[vad]->-r requirements.txt (line 4)) (3.6.0)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\projects\\ai-gateway\\.venv\\lib\\site-packages (from typer<1.0,>=0.12->gradio<6.0,>=4.0->fastrtc[vad]->-r requirements.txt (line 4)) (8.1.8)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\projects\\ai-gateway\\.venv\\lib\\site-packages (from typer<1.0,>=0.12->gradio<6.0,>=4.0->fastrtc[vad]->-r requirements.txt (line 4)) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\projects\\ai-gateway\\.venv\\lib\\site-packages (from typer<1.0,>=0.12->gradio<6.0,>=4.0->fastrtc[vad]->-r requirements.txt (line 4)) (14.0.0)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in c:\\projects\\ai-gateway\\.venv\\lib\\site-packages (from coloredlogs->onnxruntime>=1.20.1->fastrtc[vad]->-r requirements.txt (line 4)) (10.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\projects\\ai-gateway\\.venv\\lib\\site-packages (from sympy->onnxruntime>=1.20.1->fastrtc[vad]->-r requirements.txt (line 4)) (1.3.0)\n",
      "Requirement already satisfied: pyreadline3 in c:\\projects\\ai-gateway\\.venv\\lib\\site-packages (from humanfriendly>=9.1->coloredlogs->onnxruntime>=1.20.1->fastrtc[vad]->-r requirements.txt (line 4)) (3.5.4)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\projects\\ai-gateway\\.venv\\lib\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio<6.0,>=4.0->fastrtc[vad]->-r requirements.txt (line 4)) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\projects\\ai-gateway\\.venv\\lib\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio<6.0,>=4.0->fastrtc[vad]->-r requirements.txt (line 4)) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\projects\\ai-gateway\\.venv\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio<6.0,>=4.0->fastrtc[vad]->-r requirements.txt (line 4)) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='text'></a>\n",
    "### üß™ Test the Realtime API using just text\n",
    "\n",
    "üëâ Based on this [sample](https://github.com/openai/openai-python/blob/main/examples/realtime/azure_realtime.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of Portugal is Lisbon. It's a vibrant city known for its rich history, stunning architecture, and delicious food. Have you ever visited?\n"
     ]
    }
   ],
   "source": [
    "from azure.identity.aio import DefaultAzureCredential\n",
    "from openai import AsyncAzureOpenAI\n",
    "import asyncio, nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "async def main() -> None:\n",
    "    credential = DefaultAzureCredential()\n",
    "    client = AsyncAzureOpenAI(\n",
    "            azure_endpoint=f\"{apim_resource_gateway_url}/rt-audio\",\n",
    "            azure_deployment=openai_deployment_name,\n",
    "            api_key=apim_subscription_key,\n",
    "            api_version=openai_api_version)\n",
    "    async with client.beta.realtime.connect(model=openai_deployment_name) as connection:\n",
    "        await connection.session.update(session={\"modalities\": [\"text\"]})  # type: ignore\n",
    "        await connection.conversation.item.create(\n",
    "            item={\n",
    "                \"type\": \"message\",\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [{\"type\": \"input_text\", \"text\": \"What is the capital of Portugal?\"}],\n",
    "            }\n",
    "        )\n",
    "        await connection.response.create()\n",
    "        async for event in connection:\n",
    "            if event.type == \"response.text.delta\":\n",
    "                print(event.delta, flush=True, end=\"\")\n",
    "            elif event.type == \"response.text.done\":\n",
    "                print()\n",
    "            elif event.type == \"response.done\":\n",
    "                break\n",
    "    await credential.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(main())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='fastrtc'></a>\n",
    "### üß™ Test the Realtime API using FastRTC + Gradio\n",
    "FastRTC is an elegant realtime library communication library to enable you to easily and quickly build RTC application both using websockets and WebRTC.\n",
    "\n",
    "Please ensure you have run the pip command succefully to install all required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://apim-sjvzedbft54iy.azure-api.net/rt-audio\n",
      "* Running on local URL:  http://0.0.0.0:7862\n",
      "\n",
      "Could not create share link. Please check your internet connection or our status page: https://status.gradio.app.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://localhost:7862/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "webrtc_id xdeqyw2ya9\n",
      "webrtc_id hrplgfc1sx9\n",
      "webrtc_id ehedc3mj4a5\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import base64\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import gradio as gr\n",
    "import numpy as np\n",
    "import openai\n",
    "from openai import AsyncAzureOpenAI\n",
    "from dotenv import load_dotenv\n",
    "from fastapi import FastAPI\n",
    "from fastapi.responses import HTMLResponse, StreamingResponse\n",
    "from fastrtc import (\n",
    "    AdditionalOutputs,\n",
    "    AsyncStreamHandler,\n",
    "    Stream,\n",
    "    get_twilio_turn_credentials,\n",
    "    wait_for_item,\n",
    ")\n",
    "from gradio.utils import get_space\n",
    "from openai.types.beta.realtime import ResponseAudioTranscriptDoneEvent\n",
    "\n",
    "SAMPLE_RATE = 24000\n",
    "\n",
    "AZURE_OPENAI_API_ENDPOINT = apim_resource_gateway_url + \"/rt-audio\"\n",
    "print(AZURE_OPENAI_API_ENDPOINT)\n",
    "AZURE_OPENAI_API_KEY = apim_subscription_key\n",
    "AZURE_OPENAI_API_VERSION = openai_api_version\n",
    "AZURE_OPENAI_DEPLOYMENT_NAME = openai_deployment_name\n",
    "SESSION_CONFIG={\n",
    "    \"input_audio_transcription\": {\n",
    "      \"model\": \"whisper-1\"\n",
    "    },\n",
    "    \"turn_detection\": {\n",
    "      \"threshold\": 0.4,\n",
    "      \"silence_duration_ms\": 600,\n",
    "      \"type\": \"server_vad\"\n",
    "    },\n",
    "    \"instructions\": \"Your name is Amy. You're a helpful agent who responds initially with a clam British accent, but also can speak in any language as the user chooses to. Always start the conversation with a cheery hello\",\n",
    "    \"voice\": \"shimmer\",\n",
    "    \"modalities\": [\"text\", \"audio\"] ## required to solicit the initial welcome message\n",
    "    }\n",
    "\n",
    "def on_open(ws):\n",
    "    print(\"Connected to server.\")\n",
    "\n",
    "def on_message(ws, message):\n",
    "    data = json.loads(message)\n",
    "    print(\"Received event:\", json.dumps(data, indent=2))\n",
    "\n",
    "class OpenAIHandler(AsyncStreamHandler):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__(\n",
    "            expected_layout=\"mono\",\n",
    "            output_sample_rate=SAMPLE_RATE,\n",
    "            output_frame_size=480,  # In this example we choose 480 samples per frame.\n",
    "            input_sample_rate=SAMPLE_RATE,\n",
    "        )\n",
    "        self.connection = None\n",
    "        self.output_queue = asyncio.Queue()\n",
    "\n",
    "    def copy(self):\n",
    "        return OpenAIHandler()\n",
    "\n",
    "    async def welcome(self):\n",
    "        await self.connection.conversation.item.create(\n",
    "            item={\n",
    "                \"type\": \"message\",\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [{\"type\": \"input_text\", \"text\": \"what's your name?\"}],\n",
    "            }\n",
    "        )\n",
    "\n",
    "        await self.connection.response.create()\n",
    "\n",
    "    async def start_up(self):\n",
    "        \"\"\"\n",
    "        Establish a persistent realtime connection to the Azure OpenAI backend.\n",
    "        The connection is configured for server‚Äêside Voice Activity Detection.\n",
    "        \"\"\"\n",
    "        self.client = openai.AsyncAzureOpenAI(\n",
    "            azure_endpoint=AZURE_OPENAI_API_ENDPOINT,\n",
    "            azure_deployment=AZURE_OPENAI_DEPLOYMENT_NAME,\n",
    "            api_key=AZURE_OPENAI_API_KEY,\n",
    "            api_version=AZURE_OPENAI_API_VERSION,\n",
    "        )\n",
    "        # When using Azure OpenAI realtime (beta), set the model/deployment identifier\n",
    "        async with self.client.beta.realtime.connect(\n",
    "            model=AZURE_OPENAI_DEPLOYMENT_NAME  # Replace with your deployed realtime model id on Azure OpenAI.\n",
    "        ) as conn:\n",
    "            # Configure the session to use server-based voice activity detection (VAD)\n",
    "            await conn.session.update(session=SESSION_CONFIG)\n",
    "            self.connection = conn\n",
    "            await self.welcome()\n",
    "            async for event in self.connection:\n",
    "                # Handle interruptions\n",
    "                if event.type == \"input_audio_buffer.speech_started\":\n",
    "                    self.clear_queue()\n",
    "                if event.type == \"response.audio_transcript.done\":\n",
    "                    # This event signals that an audio transcription is completed.\n",
    "                    await self.output_queue.put(AdditionalOutputs(event))\n",
    "                if event.type == \"response.audio.delta\":\n",
    "                    # For incremental audio output events, decode the delta.\n",
    "                    await self.output_queue.put(\n",
    "                        (\n",
    "                            self.output_sample_rate,\n",
    "                            np.frombuffer(base64.b64decode(event.delta), dtype=np.int16).reshape(1, -1),\n",
    "                        ),\n",
    "                    )\n",
    "\n",
    "    async def receive(self, frame: tuple[int, np.ndarray]) -> None:\n",
    "        \"\"\"\n",
    "        Receives an audio frame from the stream and sends it into the realtime API.\n",
    "        The audio data is encoded as Base64 before appending to the connection's input.\n",
    "        \"\"\"\n",
    "        if not self.connection:\n",
    "            return\n",
    "        _, array = frame\n",
    "        array = array.squeeze()\n",
    "        # Encode audio as Base64 string\n",
    "        audio_message = base64.b64encode(array.tobytes()).decode(\"utf-8\")\n",
    "        await self.connection.input_audio_buffer.append(audio=audio_message)  # type: ignore\n",
    "\n",
    "    async def emit(self) -> tuple[int, np.ndarray] | AdditionalOutputs | None:\n",
    "        \"\"\"\n",
    "        Waits for and returns the next output from the output queue.\n",
    "        The output may be an audio chunk or an additional output such as transcription.\n",
    "        \"\"\"\n",
    "        return await wait_for_item(self.output_queue)\n",
    "\n",
    "    async def shutdown(self) -> None:\n",
    "        if self.connection:\n",
    "            await self.connection.close()\n",
    "            self.connection = None\n",
    "\n",
    "def update_chatbot(chatbot: list[dict], response: ResponseAudioTranscriptDoneEvent):\n",
    "    \"\"\"\n",
    "    Append the completed transcription (from Azure OpenAI) to the chatbot messages.\n",
    "    \"\"\"\n",
    "    chatbot.append({\"role\": \"assistant\", \"content\": response.transcript})\n",
    "    return chatbot\n",
    "\n",
    "\n",
    "# Create the Gradio Chatbot component for displaying conversation messages.\n",
    "chatbot = gr.Chatbot(type=\"messages\")\n",
    "latest_message = gr.Textbox(type=\"text\", visible=True)\n",
    "\n",
    "# Instantiate the Stream object that uses the OpenAIHandler.\n",
    "stream = Stream(\n",
    "    OpenAIHandler(),\n",
    "    mode=\"send-receive\",\n",
    "    modality=\"audio\",\n",
    "    additional_inputs=[chatbot],\n",
    "    additional_outputs=[chatbot],\n",
    "    additional_outputs_handler=update_chatbot,\n",
    ")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    stream.ui.launch(server_name=\"0.0.0.0\", server_port=7862, share=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='clean'></a>\n",
    "### üóëÔ∏è Clean up resources\n",
    "\n",
    "When you're finished with the lab, you should remove all your deployed resources from Azure to avoid extra charges and keep your Azure subscription uncluttered.\n",
    "Use the [clean-up-resources notebook](clean-up-resources.ipynb) for that."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
